{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ba67fa",
   "metadata": {},
   "source": [
    "para iniciar nuestro desafio final tenemos que realizar la instalacion y configuracion\n",
    "de postgres en python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#primero instalaremos el conector de python y postgres pero antes debemos\n",
    "#ir a nuestra consola y actuañizar pip, posteriormente instalar el conector por pip\n",
    "#para asi importa el modulo psycopg2\n",
    "#el comando de la consola o terminal es pip install psycopg2-binary\n",
    "#revisar si tenemos python en nuestras variables de entorno sino no podras instalarlo\n",
    "#al instalar python te permite dejarlo como path (variable de entorno)\n",
    "#ya tenermos instalado via pip la libreria, procedemos a importarlo en nuestro cuaderno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a606022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57a6705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la conextion segun la documentacion de postgres y python\n",
    "#como tenemos nuestra bd en localhost le damos los parametros locales\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"classicmodels\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Admin\",\n",
    "    host=\"localhost\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa32a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con el objeto cursos nos permite conectar y poder crear las consultas\n",
    "#a nuestra base de datos, tambien esta en la documentacion de postgres y python\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37e5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para ejecutar o lanzar el cursor usamos el .execute y la \"query\" \n",
    "#esta es ejecutada pero necesitamos ver los datos en nuestro cuaderno y para ero utilizaremos rowsi\n",
    "cur.execute(\"SELECT * FROM customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd1ad33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 'Atelier graphique', 'Schmitt', 'Carine ', '40.32.2555', '54, rue Royale', None, 'Nantes', None, '44000', 'France', 1370.0, 21000.0)\n"
     ]
    }
   ],
   "source": [
    "#aqui creamos la var rows y ejecutamos el cursos, existen 3 tipos de fecth para ver los datos\n",
    "#por ejemplo usamos el many que muestra algunos, esta el fetchall y el fecthone\n",
    "#utilizamos un for para que recorramos los datos y al final el print de donde queda almacenado(row)\n",
    "rows = cur.fetchmany()\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45cb76b",
   "metadata": {},
   "source": [
    "podemos concluir que se hizo la coneccion y que si ejecutamos una query nos muestra los datos\n",
    "CONTINUAMOS CON NUESRO DESAFIO"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb634b7b",
   "metadata": {},
   "source": [
    "El área comercial de una empresa pide realizar un cierre de año de las ventas, tanto para\n",
    "revisar si las metas fueron cumplidas, como para poder planificar el siguiente año. Para ello,\n",
    "considerarán los datos del dataset classicmodels.sql para responder algunas preguntas,\n",
    "realizando las siguientes tareas.\n",
    "1. Genera una función llamada leer_tabla(tabla, engine) y utilízala para leer tablas\n",
    "completas desde la base de datos en dataframes independientes. Utilizando esta\n",
    "función, importa las siguientes tablas:\n",
    "- order\n",
    "- orderdetails\n",
    "- customers\n",
    "- products\n",
    "- employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35faab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tal como nos pide la prueba final, creamos la funcion \"leer tabla\" junto a una query\n",
    "#importamos pandas para leer la misma consulta almacenada\n",
    "import pandas as pd\n",
    "\n",
    "def leer_tabla(tabla, engine):\n",
    "    #creamos la query que nos ayudara a leer la tabla, ojo es muy impante dejar {tablas}\n",
    "    #ya que sera una lista que asignaremos a los nombres de todas las tablas\n",
    "    #la cual leera\n",
    "    consulta = f\"SELECT * FROM {tabla}\"\n",
    "    \n",
    "    #leemos la tabla en un dataframe utilizando pd.read_sql() y en el parentesis van \n",
    "    #los argumentos de la consulta\n",
    "    df = pd.read_sql(consulta, engine)\n",
    "    \n",
    "    #devolvemos el dataframe\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01035a9f",
   "metadata": {},
   "source": [
    "2. Realiza el cruce entre los DataFrames, asegurándote de utilizar correctamente el\n",
    "parámetro validate para asegurar la integridad referencial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bba9d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   orderNumber   orderDate requiredDate shippedDate   status  \\\n",
      "0        10100  2003-01-06   2003-01-13  2003-01-10  Shipped   \n",
      "1        10379  2005-02-10   2005-02-18  2005-02-11  Shipped   \n",
      "2        10173  2003-11-05   2003-11-15  2003-11-09  Shipped   \n",
      "3        10331  2004-11-17   2004-11-23  2004-11-23  Shipped   \n",
      "4        10110  2003-03-18   2003-03-24  2003-03-20  Shipped   \n",
      "\n",
      "                                            comments  customerNumber  \\\n",
      "0                                               None             363   \n",
      "1                                               None             141   \n",
      "2  Cautious optimism. We have happy customers her...             278   \n",
      "3  Customer requested special shippment. The inst...             486   \n",
      "4                                               None             187   \n",
      "\n",
      "  productCode  quantityOrdered  priceEach  ...  salesRepEmployeeNumber  \\\n",
      "0    S18_1749               30      136.0  ...                  1216.0   \n",
      "1    S18_1749               39      156.4  ...                  1370.0   \n",
      "2    S18_1749               24      168.3  ...                  1401.0   \n",
      "3    S18_1749               44      154.7  ...                  1323.0   \n",
      "4    S18_1749               42      153.0  ...                  1501.0   \n",
      "\n",
      "  creditLimit               productName   productLine productScale  \\\n",
      "0    114200.0  1917 Grand Touring Sedan  Vintage Cars         1:18   \n",
      "1    227600.0  1917 Grand Touring Sedan  Vintage Cars         1:18   \n",
      "2    119600.0  1917 Grand Touring Sedan  Vintage Cars         1:18   \n",
      "3     72600.0  1917 Grand Touring Sedan  Vintage Cars         1:18   \n",
      "4    136800.0  1917 Grand Touring Sedan  Vintage Cars         1:18   \n",
      "\n",
      "               productVendor  \\\n",
      "0  Welly Diecast Productions   \n",
      "1  Welly Diecast Productions   \n",
      "2  Welly Diecast Productions   \n",
      "3  Welly Diecast Productions   \n",
      "4  Welly Diecast Productions   \n",
      "\n",
      "                                  productDescription quantityInStock buyPrice  \\\n",
      "0  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "1  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "2  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "3  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "4  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "\n",
      "    MSRP  \n",
      "0  170.0  \n",
      "1  170.0  \n",
      "2  170.0  \n",
      "3  170.0  \n",
      "4  170.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "#primero debemos leer las tablas y para eso debemos recorrer la lista de tablas\n",
    "#en la consulta, le diremos que lea todas las tablas\n",
    "def leer_tabla(tabla, engine):\n",
    "    consulta = f\"SELECT * FROM {tabla}\"\n",
    "    df = pd.read_sql(consulta, engine)\n",
    "    return df\n",
    "\n",
    "#le damos la var de la conexion la cual segun la documentacion\n",
    "#debemos crearla asi postgresql://usuario:contraseña@localhost:puerto/nombre_de_base_de_datos\n",
    "cadena_conexion = 'postgresql://postgres:Admin@localhost:5432/classicmodels'\n",
    "\n",
    "#creamos el objeto engine para crear la conexion\n",
    "engine = create_engine(cadena_conexion)\n",
    "\n",
    "#en la lista tablas, ingresamos nuestras tablas de la base de datos del desafio\n",
    "tablas = ['orders', 'orderdetails', 'customers', 'products', 'employees']\n",
    "\n",
    "#y para almacenar las tablas creamos el diccionario de los DF \n",
    "dataframes = {}\n",
    "\n",
    "#el resultado de las tablas los recorremos con un for y almacenamos en tabla, indicandole\n",
    "#que sean ingresados al dataframe(diccionario)\n",
    "for tabla in tablas:\n",
    "    dataframes[tabla] = leer_tabla(tabla, engine)\n",
    "\n",
    "#luego para realizar el cruce debemos verificar la integridad referencial utilizando el metodo Merge\n",
    "#y los parameteros validad, verificando si las claves de los DF son unicas, sino este nos arrojara\n",
    "#errores (despues de varios errores) verificamos segun la db como las primary key(en este caso no) \n",
    "#pero son los identificadores de las tablas\n",
    "# Utilizando merge y el parámetro validate\n",
    "merged_df = pd.merge(dataframes['orders'], dataframes['orderdetails'], on='orderNumber', validate='one_to_many')\n",
    "merged_df = pd.merge(merged_df, dataframes['customers'], on='customerNumber', validate='many_to_one')\n",
    "merged_df = pd.merge(merged_df, dataframes['products'], on='productCode', validate='many_to_one')\n",
    "\n",
    "\n",
    "#y printeamos las cabeceras de las tablas con el head\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7dbba4b",
   "metadata": {},
   "source": [
    "3. Agrega las siguientes columnas, considerando su nombre y la fórmula asociada\n",
    "- venta: quantityOrdered*priceEach\n",
    "- costo: quantityOrdered*buyPrice\n",
    "- ganancia: considerando las columnas anteriores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9037dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   orderNumber   orderDate requiredDate shippedDate   status  \\\n",
      "0        10100  2003-01-06   2003-01-13  2003-01-10  Shipped   \n",
      "1        10379  2005-02-10   2005-02-18  2005-02-11  Shipped   \n",
      "2        10173  2003-11-05   2003-11-15  2003-11-09  Shipped   \n",
      "3        10331  2004-11-17   2004-11-23  2004-11-23  Shipped   \n",
      "4        10110  2003-03-18   2003-03-24  2003-03-20  Shipped   \n",
      "\n",
      "                                            comments  customerNumber  \\\n",
      "0                                               None             363   \n",
      "1                                               None             141   \n",
      "2  Cautious optimism. We have happy customers her...             278   \n",
      "3  Customer requested special shippment. The inst...             486   \n",
      "4                                               None             187   \n",
      "\n",
      "  productCode  quantityOrdered  priceEach  ...   productLine productScale  \\\n",
      "0    S18_1749               30      136.0  ...  Vintage Cars         1:18   \n",
      "1    S18_1749               39      156.4  ...  Vintage Cars         1:18   \n",
      "2    S18_1749               24      168.3  ...  Vintage Cars         1:18   \n",
      "3    S18_1749               44      154.7  ...  Vintage Cars         1:18   \n",
      "4    S18_1749               42      153.0  ...  Vintage Cars         1:18   \n",
      "\n",
      "               productVendor  \\\n",
      "0  Welly Diecast Productions   \n",
      "1  Welly Diecast Productions   \n",
      "2  Welly Diecast Productions   \n",
      "3  Welly Diecast Productions   \n",
      "4  Welly Diecast Productions   \n",
      "\n",
      "                                  productDescription quantityInStock buyPrice  \\\n",
      "0  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "1  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "2  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "3  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "4  This 1:18 scale replica of the 1917 Grand Tour...            2724     86.7   \n",
      "\n",
      "    MSRP   venta   costo ganancia  \n",
      "0  170.0  4080.0  2601.0   1479.0  \n",
      "1  170.0  6099.6  3381.3   2718.3  \n",
      "2  170.0  4039.2  2080.8   1958.4  \n",
      "3  170.0  6806.8  3814.8   2992.0  \n",
      "4  170.0  6426.0  3641.4   2784.6  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "#agregamos la columna venta (venta = quantityOrdered * priceEach)\n",
    "merged_df['venta'] = merged_df['quantityOrdered'] * merged_df['priceEach']\n",
    "#Agregamos la columna costo (costo = quantityOrdered * buyPrice)\n",
    "merged_df['costo'] = merged_df['quantityOrdered'] * merged_df['buyPrice']\n",
    "#Agregamos la columna ganancia (ganancia = venta - costo)\n",
    "merged_df['ganancia'] = merged_df['venta'] - merged_df['costo']\n",
    "#printeamos las 5 primeras filas\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc4c9742",
   "metadata": {},
   "source": [
    "4. ¿Cuál fue el total de ventas por línea de productos? Incluye una fila de totales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ccab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    productCode       venta\n",
      "0      S10_1678    90157.77\n",
      "1      S10_1949   190017.96\n",
      "2      S10_2016   109998.82\n",
      "3      S10_4698   170686.00\n",
      "4      S10_4757   127924.32\n",
      "..          ...         ...\n",
      "105   S700_3962    78919.06\n",
      "106   S700_4002    71753.93\n",
      "107    S72_1253    42692.53\n",
      "108    S72_3212    47550.40\n",
      "109       Total  9604190.61\n",
      "\n",
      "[110 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#calculamos el dotal de ventas por producto\n",
    "ventas_por_producto = merged_df.groupby('productCode')['venta'].sum().reset_index()\n",
    "\n",
    "#calculamos el total de las ventas de productos\n",
    "total_ventas = ventas_por_producto['venta'].sum()\n",
    "\n",
    "#ahora creamos la fila de totales\n",
    "total_fila = {'productCode': 'Total', 'venta': total_ventas}\n",
    "\n",
    "#pasamos la fila a un df\n",
    "total_df = pd.DataFrame([total_fila])\n",
    "\n",
    "#unimos el df de total al df de las ventas por producto\n",
    "ventas_por_producto = pd.concat([ventas_por_producto, total_df], ignore_index=True)\n",
    "\n",
    "#y printeamos el resultado\n",
    "print(ventas_por_producto)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15244ec1",
   "metadata": {},
   "source": [
    "5. ¿Cuántos clientes distintos hicieron compras?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2183d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de clientes distintos que hicieron compras es: 98\n"
     ]
    }
   ],
   "source": [
    "#nos vamos a la tabla custormesnumber y calculamos quienes hicieron compras\n",
    "clientes_distintos = merged_df['customerNumber'].nunique()\n",
    "#printeamos el resultado\n",
    "print(\"La cantidad de clientes distintos que hicieron compras es:\", clientes_distintos)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ca86ef1",
   "metadata": {},
   "source": [
    "¿Existen clientes que aún no han hecho ninguna compra? ¿Cuántos son?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "904c3e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de clientes que aún no han realizado ninguna compra: 0\n"
     ]
    }
   ],
   "source": [
    "#listamos los clientes\n",
    "todos_los_clientes = merged_df['customerNumber'].unique()\n",
    "#revisamos quienes si hicieron compras\n",
    "clientes_con_compras = merged_df['customerNumber'].unique()\n",
    "#buscamos los que no\n",
    "clientes_sin_compras = set(todos_los_clientes)-set(clientes_con_compras)\n",
    "#con len calculamos la cantidad que no compraron segun el resultado de arriba\n",
    "cantidad_clientes_sin_compras = len(clientes_sin_compras)\n",
    "#printeamos el resultado\n",
    "print(\"Cantidad de clientes que aún no han realizado ninguna compra:\", cantidad_clientes_sin_compras)\n",
    "#segun esto deberia dar 0 ya que de igual forma consulte la bd\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ebfdaad",
   "metadata": {},
   "source": [
    "7. Se solicita la creación de dos reportes, que respondan las preguntas dadas\n",
    "● ¿Cuáles fueron los 10 clientes que reportan mayores ventas brutas en dinero durante\n",
    "el año 2005? Genera un DataFrame y guárdalo en una tabla de Postgre llamada\n",
    "top_10_clientes_2005, en la que se especifique el nombre del cliente y su\n",
    "correspondiente venta, costo y ganancia.\n",
    "● ¿Cuál fue el top 10 de artículos más vendidos durante el año 2005 (considerando\n",
    "cantidad neta)? Genera un DataFrame y guárdalo en una tabla de Postgre llamada\n",
    "top_10_productos_2005, en la que se especifique el nombre del producto y su\n",
    "correspondiente venta, costo y ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0d9a3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 clientes con maores ventas brutas\n",
    "#primero revisaremos los datos del 2005 y creamos la var\n",
    "ventas_2005 = merged_df[merged_df['orderDate'].dt.year == 2005]\n",
    "#calculamos las ventas brutas de los clientes y los agrupamos\n",
    "ventas_por_cliente = ventas_2005.groupby('customerName')[['venta', 'costo', 'ganancia']].sum().reset_index()\n",
    "\n",
    "#ordenaremos en orden descendente \n",
    "top_10_clientes = ventas_por_cliente.nlargest(10, 'venta')\n",
    "#y lo almacenamos como una vista en postgres y un df en python\n",
    "top_10_clientes.to_sql('top_10_clientes_2005', engine, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53b620d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   customerName      venta      costo   ganancia\n",
      "0        Euro+ Shopping Channel  290018.52  169989.97  120028.55\n",
      "1  Mini Gifts Distributors Ltd.  192481.73  115084.72   77397.01\n",
      "2             La Rochelle Gifts   91147.11   55527.04   35620.07\n",
      "3     The Sharp Gifts Warehouse   83984.89   50843.02   33141.87\n",
      "4    Down Under Souveniers, Inc   75020.13   46389.52   28630.61\n",
      "5       Anna's Decorations, Ltd   56932.30   35414.90   21517.40\n",
      "6         Salzburg Collectables   52420.07   33536.26   18883.81\n",
      "7             Gifts4AllAges.com   50806.85   33221.25   17585.60\n",
      "8      Corporate Gift Ideas Co.   46781.66   28561.31   18220.35\n",
      "9       Oulu Toy Supplies, Inc.   46770.52   27493.61   19276.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FpymeTarapaca\\AppData\\Local\\Temp\\ipykernel_14952\\388440641.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_query, conn)\n"
     ]
    }
   ],
   "source": [
    "#recordemos que ya creamos la tabla arriba, ahora solo queda consultar\n",
    "sql_query = \"SELECT * FROM top_10_clientes_2005\"\n",
    "\n",
    "#ejecutamos la query y la almacenamos en el df\n",
    "df = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "#printeamos el dataframe de los nombres\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3e0622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'top_10_productos_2005' guardada en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#nuevamente creamos la conexion con la bd\n",
    "cadena_conexion = 'postgresql://postgres:Admin@localhost:5432/classicmodels'\n",
    "engine = create_engine(cadena_conexion)\n",
    "\n",
    "#filtraremos los datos de venta del año 2005\n",
    "ventas_2005 = merged_df[merged_df['orderDate'].dt.year == 2005]\n",
    "\n",
    "#con los mismos paratemos dee venta, costo, ganancia y cantidad hacemos el calculo\n",
    "productos_2005 = ventas_2005.groupby('productName').agg(\n",
    "    venta=('venta', 'sum'),\n",
    "    costo=('costo', 'sum'),\n",
    "    ganancia=('ganancia', 'sum'),\n",
    "    cantidad_neta=('quantityOrdered', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "#revisamos la cantidad neta de los 10 productos(ojo los primeros)\n",
    "top_10_productos = productos_2005.nlargest(10, 'cantidad_neta')\n",
    "\n",
    "#nuevamente creamos una tabla de los top 10 productos del 2004\n",
    "top_10_productos.to_sql('top_10_productos_2005', engine, index=False, if_exists='replace')\n",
    "\n",
    "#y nos printeamos si lo ha hecho( ya que varias veces me daba error agregue este print)\n",
    "print(\"Tabla 'top_10_productos_2005' guardada en la base de datos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51738c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               productName     venta     costo  ganancia  \\\n",
      "0              1992 Ferrari 360 Spider red  52978.28  27031.30  25946.98   \n",
      "1                       1969 Dodge Charger  29567.27  15974.56  13592.71   \n",
      "2                        1997 BMW R 1100 S  28747.69  16493.06  12254.63   \n",
      "3                         1997 BMW F650 ST  22469.91  17198.44   5271.47   \n",
      "4                  1956 Porsche 356A Coupe  31432.14  25066.50   6365.64   \n",
      "5                 1960 BSA Gold Star DBD34  16049.47   9031.44   7018.03   \n",
      "6                  1900s Vintage Tri-Plane  15940.74   8622.74   7318.00   \n",
      "7                         2002 Suzuki XREO  30434.09  15308.37  15125.72   \n",
      "8                    1996 Moto Guzzi 1100i  26139.34  15867.70  10271.64   \n",
      "9  1941 Chevrolet Special Deluxe Cabriolet  20918.96  14595.08   6323.88   \n",
      "\n",
      "   cantidad_neta  \n",
      "0            347  \n",
      "1            272  \n",
      "2            271  \n",
      "3            257  \n",
      "4            255  \n",
      "5            242  \n",
      "6            238  \n",
      "7            231  \n",
      "8            230  \n",
      "9            226  \n"
     ]
    }
   ],
   "source": [
    "#vamos a ver la tabla y sus productos\n",
    "df_top_10_productos_2005 = pd.read_sql_table('top_10_productos_2005', engine)\n",
    "\n",
    "#printeamos el df\n",
    "print(df_top_10_productos_2005)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a961a44",
   "metadata": {},
   "source": [
    "Para este punto debes aplicar el principio DRY, por lo que se deben utilizar funciones para\n",
    "realizar el filtrado por fechas, generar tablas pivote y escribir tabla en Postgre. Las funciones\n",
    "deben estar en un archivo separado llamado funciones.py y ser importadas al Jupyter\n",
    "Notebook. En este archivo se debe incluir:\n",
    "● Una función que permita filtrar un DataFrame por fechas, indicando dataframe,\n",
    "columna para filtrar, fecha inicio y fecha fin. La función debe retornar un DataFrame.\n",
    "● Una función que permita generar reportes dependiendo de parámetros de entrada\n",
    "como dataframe, filas, columnas, valores y medida (funcion_agrupadora). Utilizar\n",
    "fill_value = 0. Esta función debe retornar un DataFrame pivotado.\n",
    "● Una función que permita escribir en la base de datos a través del guardado de un\n",
    "DataFrame dependiendo de parámetros de entrada como DataFrame, nombre de la\n",
    "tabla, engine y comportamiento en caso de que exista la tabla (if_exists)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f3731",
   "metadata": {},
   "source": [
    "esta funcion esta guardada en otro archivo como funciones.py\n",
    "la idea es reutilizar esta fucncion para consultar las fechas y generar el reporte, ademas\n",
    "despues de consultar y hacer la tabla pivot del df.\n",
    "\n",
    "import pandas as pc\n",
    "def filtrar_por_fechas(dataframe, columna_fecha, fecha_inicio, fecha_fin):\n",
    "    return dataframe[(dataframe[columna_fecha] >= fecha_inicio) & (dataframe[columna_fecha] <= fecha_fin)]\n",
    "    \n",
    "    esta funcion toma un Df, el nombre de la columna que contiene las fechas, asi como una fecha de inicio y una fecha de fin como argumentos, filtra el df para incluir solo las filas que tienen fechas dentro del rango especificado (fecha_inicio <= columna <= fecha_fin) y devuelve el DF resultante\n",
    "\n",
    "def generar_reporte_pivot(dataframe, filas, columnas, valores, funcion_agrupadora):\n",
    "    pivote = pd.pivot_table(dataframe, index=filas, columns=columnas, values=valores, aggfunc=funcion_agrupadora, fill_value=0)\n",
    "    return pivote\n",
    "\n",
    "    esta funcion realiza una operación de pivote en el df proporcionado yoma como entrada el df, las columnas que se usaran como filas en la tabla pivotada, las columnas que se utilizaran como columnas en la tabla pivotada, las columnas cuyos valores se utilizarán en la tabla pivotada y una funcion de agregación (por ejemplo, suma, promedio) devuelve un nuevo DataFrame pivotadop\n",
    "    \n",
    "def escribir_en_postgres(dataframe, nombre_tabla, engine, if_exists):\n",
    "    dataframe.to_sql(nombre_tabla, engine, if_exists=if_exists, index=False)\n",
    "    \n",
    "    esta funcion toma un df el nombre de la tabla en la base de datos postgreql donde se escribirán los datos,un argumento if_exists que indica qué hacer si la tabla ya existe en la base de datos que reemplaza los nuevos datos  La función escribe los datos del df en la tabla especificada en la base de datos postgresql.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46cc0409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from funciones import filtrar_por_fechas, generar_reporte_pivot, escribir_en_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d0aa6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso de las funciones\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m filtrar_por_fechas(dataframe, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m reporte_pivot \u001b[38;5;241m=\u001b[39m generar_reporte_pivot(df_filtrado, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcliente\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducto\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcantidad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28msum\u001b[39m)\n\u001b[0;32m      6\u001b[0m escribir_en_postgres(reporte_pivot, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreporte_ventas\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de las funciones\n",
    "df_filtrado = filtrar_por_fechas(dataframe, 'fecha', '2022-01-01', '2022-12-31')\n",
    "\n",
    "reporte_pivot = generar_reporte_pivot(df_filtrado, ['cliente'], ['producto'], 'cantidad', sum)\n",
    "\n",
    "escribir_en_postgres(reporte_pivot, 'reporte_ventas', engine, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c862c0a",
   "metadata": {},
   "source": [
    "bueno no pude comprobar usando e importando las funciones, nose por que el df me sale como no definito siendo que esta en funciones py con pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
